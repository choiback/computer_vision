{"cells":[{"cell_type":"markdown","metadata":{"id":"sV6MGVlyCYcp"},"source":["# MBA FIAP Inteligência Artificial & Machine Learning\n","\n","## Visão Computacional: Análise de Imagens Médicas\n","\n","> Atenção: este notebook foi desenhado para funcionar no **Google Collab**.\n","\n","\n","## 1. Introdução\n","\n","Uma determinada fintech focada em consumidores finais pessoa física constataou um grande número de fraudes em transações bancárias.\n","\n","O setor de fraudes apontou que existem clientes que se queixaram de não contratar serviços específicos, como o crédito pessoal, e após isso transferir para outras contas desconhecidas.\n","\n","Após análises pelas equipes de segurança, os protocolos de utilização da senha foram realizados em conformidade, ou seja, cada cliente autenticou com sua própria senha de maneira regular.\n","\n","Em função disso, o banco precisa arcar com reembolsos e medidas de contenção para evitar processos judiciais, pois os clientes alegam terem sido invadidos por hackers ou algo parecido.\n","\n","Uma das formas de solucionar ou minimizar este problema é com a utilização de outras formas de autenticação, sobretudo em operações críticas, como a obtenção de crédito pessoal.\n","\n","Desta forma podemos implementar uma verificação de identidade com prova de vida (liveness), que utilize uma verificação e identificação facial.\n","\n","Caso o cliente não seja autenticado, ele será atendido por uma esteira dedicada e as evidências da não identificação serão encaminhadas para a área de IA para validação dos parâmetros e limiares para aperfeiçoamento do modelo.\n","\n","Será necessário construir:\n","\n","* Detector de faces\n","* Identificação de faces (podendo ser um comparador entre um rosto de documento e outra da prova de vida)\n","* Detecção de vivacidade (liveness) para evitar que um fraudador utilize uma foto estática.\n","\n","\n",">Formas alternativas de prover a identificação e prova de vivacidade, além destas que foram solicitadas poderão ser submetidas.\n","\n","\n","<p align=\"center\">\n","    <img src=\"https://github.com/michelpf/fiap-ml-visao-computacional-detector-liveness/blob/master/notebook/imagens/liveness.jpg?raw=1\">\n","</p>\n","\n","Imagem retirada do [Grunge](https://www.grunge.com/192826/company-testing-robocop-facial-recognition-software-with-us-police/).\n","\n","## 2. Instruções\n","\n","Este projeto final tem como objetivo explorar os conhecimentos adquiridos nas aulas práticas.\n","\n","Iremos constuir uma forma de validar se uma determinada imagem foi ou não adulterada e se trata de uma produção fraudade.\n","\n","Existem diversas formas de validar a vivacidade, e neste sentido conto com a criatividade de vocês dado que já dominam encontrar uma face numa imagem, aplicar marcos faciais e até mesmo construir uma rede neural convulacional.\n","\n","A abordagem mais simples é pela construção de uma rede neural com imagens de fotos de rostos de outras fotos e fotos de rostos sem modificações. Tal classificador deverá classificar se dada imagem possui vivacidade ou não com uma pontuação de probabilidade.\n","\n","Referências que abordam o tema para servir de inspiração:\n","\n","1. [PyImageSearch](https://pyimagesearch.com/2019/03/11/liveness-detection-with-opencv/), Liveness detection with OpenCV;\n","2. [Kickertech](https://kickertech.com/face-liveness-detection-via-opencv-and-tensorflow/), Liveness detection via OpenCV and Tensorflow.\n","3. [Towards Data Science](https://towardsdatascience.com/real-time-face-liveness-detection-with-python-keras-and-opencv-c35dc70dafd3?gi=24f8e1b740f9), Real-time face liveness detection with Python, Keras and OpenCV.\n","\n","Este projeto poderá ser feita por grupos de até 4 pessoas.\n","Caso este projeto seja substitutivo, deverá ser realizado por apenas uma pessoa.\n","\n","| Nome dos Integrantes     | RM            | Turma |\n","| :----------------------- | :------------ | :-----: |\n","| Marky Santana            | RM 348228     | 3DTSR |\n","| Guilherme Seganzerla     | RM 348256     | 3DTSR |\n","| Raphael Choi             | RM 348188     | 3DTSR |"]},{"cell_type":"markdown","metadata":{"id":"f3s9JNlFCYc-"},"source":["## 3. Abordagem e organização da solução do problema (2 pontos)\n","\n","Como o grupo pretende deteccar a prova de vivacidade de uma determinada imagem? Quais os passos e os building blocks deste processo?"]},{"cell_type":"markdown","metadata":{"id":"asZ7Nb0HCYc_"},"source":["**Resposta**:"]},{"cell_type":"markdown","source":["...\n","\n","Para nossa arquitetura vamos trabalhar com 3 blocos de reconhecimento nas imagens:\n","\n","Utilizando uma imagem ou video >\n","\n","###1º Treinaremos um modelo de CNN capaz de identificar rostos reais e rostos fakes.\n","Para este processo seguiremos:\n","- Preparamos um dataset proprietário com fotos dos integrantes do grupo e algumas fotos de sites separando 70% das imagens para treino e 30% para teste.\n","- Escolhemos o modelo \"Keras\" que irá aplicar algumas camadas de convolução, maxpooling, uma camada de flaten e uma saida de camada densa com ativação \"sigmoid\"\n","- Para as metricas do modelo serão utilizadas loss='binary_crossentropy', optimizer='adam', metrics='accuracy'\n","- O modelo será treinado em 25 épocas e esperamos uma acurácia superior a 80% dado nosso dataset.\n","\n","###2º Iremos aplicar o modelo de reconhecimento de rostos.\n","Para este processo escolhemos o HAAR Cascade \"haarcascade_frontalface_default.xml\", pois o modelo já esta treinado para reconhecer faces em uma imagem. Alem de reconhecer um rosto, utilizaremos a biblioteca do CV2 para desenhar um retangulo em volta do rosto, assim facilitando a visualização.\n","\n","###3º Como prova de vida \"Liveness Detection\" optamos por utilizar tambem o HAAR Cascade \"haarcascade_smile.xml\".\n","Será solicitado ao cliente que grave um video dele proprio sorrindo. Aplicaremos o reconhecimento de rostos para reduzir a área de busca e assim identificar se o rosto da imagem esta sorindo. Da mesma forma, aplicaremos bordas em volta do sorriso para melhor visualização do modelo aplicado."],"metadata":{"id":"FBSrEdaqn9jD"}},{"cell_type":"markdown","metadata":{"id":"tzzcSJXdCYdB"},"source":["## 4 Desenvolvimento da solução (5,5 pontos)\n","\n","Detalhe o passo-a-passo do algoritmo de deteção de vivacidade.\n","Se optar pela construção e treinamento de um modelo de redes neurais convulucionais, apresente a arquitetura, prepare os dados de treinamento, realize o treinamento."]},{"cell_type":"markdown","metadata":{"id":"Aq-9Su6ACYdC"},"source":["### 4.1 Organização de dados para treinamento de modelo de liveness (2 pontos)"]},{"cell_type":"markdown","source":["Baixando o conteudo do Github para usar o dataset com as imagens para treinar o modelo e baixado bibliotecas que serão usado no modelo"],"metadata":{"id":"1hCmY3uHfbUA"}},{"cell_type":"code","source":["!git clone https://github.com/choiback/computer_vision"],"metadata":{"id":"hIR9uaHHCKw-","executionInfo":{"status":"ok","timestamp":1707702431846,"user_tz":180,"elapsed":2691,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}},"outputId":"9fa05fab-f391-4e73-c159-4ac65fe808c4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'computer_vision'...\n","remote: Enumerating objects: 273, done.\u001b[K\n","remote: Counting objects: 100% (233/233), done.\u001b[K\n","remote: Compressing objects: 100% (218/218), done.\u001b[K\n","remote: Total 273 (delta 71), reused 103 (delta 13), pack-reused 40\u001b[K\n","Receiving objects: 100% (273/273), 37.14 MiB | 31.22 MiB/s, done.\n","Resolving deltas: 100% (76/76), done.\n"]}]},{"cell_type":"code","source":["!pip install face_recognition"],"metadata":{"id":"tTgCk6dcEng6","executionInfo":{"status":"ok","timestamp":1707702474920,"user_tz":180,"elapsed":43079,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}},"outputId":"091c676c-6982-48eb-d983-e18290cec8b0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0 (from face_recognition)\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=01f97200b3dafd5c00d8f4d1c1acbdb1cc55bcec94059493d36fdb4f2b663c5e\n","  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"]}]},{"cell_type":"markdown","source":["Importando as bibliotecas necessarias para rodar o modelo"],"metadata":{"id":"YvSNKSY2gEIJ"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"Cq8cXWSzCYdE","executionInfo":{"status":"ok","timestamp":1707702486878,"user_tz":180,"elapsed":12004,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","from collections import defaultdict\n","from imutils.video import VideoStream\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import AveragePooling2D, MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense, Dropout\n","from keras.models import model_from_json\n","from keras.preprocessing.image import ImageDataGenerator\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","source":["Criando função para detectar face no videos (video precisar ter 90% dos frames com uma face)"],"metadata":{"id":"_srmx2_l-6OD"}},{"cell_type":"code","source":["def detect_faces_in_video(video_path):\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    face_count = 0\n","\n","    for _ in tqdm(range(frame_count)):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","\n","        if len(faces) > 0:\n","            face_count += 1\n","\n","    cap.release()\n","\n","    if face_count / frame_count >= 0.9:\n","        return True\n","    else:\n","        return False"],"metadata":{"id":"c58Xy0wuqfMx","executionInfo":{"status":"ok","timestamp":1707702486880,"user_tz":180,"elapsed":20,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Tratando e separando as imangens de treino e teste que o modelo irar usar para validar se é uma imagem fake ou não"],"metadata":{"id":"SKyVpJuF_FJ3"}},{"cell_type":"code","source":["IMG_SIZE = 24\n","\n","def collect():\n","\ttrain_datagen = ImageDataGenerator(\n","\t\t\trescale=1./255,\n","\t\t\tshear_range=0.2,\n","\t\t\thorizontal_flip=True,\n","\t\t)\n","\n","\tval_datagen = ImageDataGenerator(\n","\t\t\trescale=1./255,\n","\t\t\tshear_range=0.2,\n","\t\t\thorizontal_flip=True,\t\t)\n","\n","\ttrain_generator = train_datagen.flow_from_directory(\n","\t    directory=\"/content/computer_vision/images/train\",\n","\t    target_size=(IMG_SIZE, IMG_SIZE),\n","\t    color_mode=\"grayscale\",\n","\t    batch_size=32,\n","\t    class_mode=\"binary\",\n","\t    shuffle=True,\n","\t    seed=42\n","\t)\n","\n","\tval_generator = val_datagen.flow_from_directory(\n","\t    directory=\"/content/computer_vision/images/test\",\n","\t    target_size=(IMG_SIZE, IMG_SIZE),\n","\t    color_mode=\"grayscale\",\n","\t    batch_size=32,\n","\t    class_mode=\"binary\",\n","\t    shuffle=True,\n","\t    seed=42\n","\t)\n","\treturn train_generator, val_generator"],"metadata":{"id":"LFLOplKQiPv9","executionInfo":{"status":"ok","timestamp":1707702486880,"user_tz":180,"elapsed":18,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y1Hb6WDXCYdJ"},"source":["### 4.2 Treinamento de modelo de liveness (1,5 pontos)"]},{"cell_type":"markdown","source":["Função para salvar o modelo"],"metadata":{"id":"CWyYGR_K_bxD"}},{"cell_type":"code","source":["def save_model(model):\n","\tmodel_json = model.to_json()\n","\twith open(\"model.json\", \"w\") as json_file:\n","\t\tjson_file.write(model_json)\n","\t# serialize weights to HDF5\n","\tmodel.save_weights(\"model.h5\")"],"metadata":{"id":"FyycdrKUjBzj","executionInfo":{"status":"ok","timestamp":1707702487526,"user_tz":180,"elapsed":13,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Função para carregar o modelo"],"metadata":{"id":"6GGtJOPw_fG_"}},{"cell_type":"code","source":["def load_model():\n","\tjson_file = open('model.json', 'r')\n","\tloaded_model_json = json_file.read()\n","\tjson_file.close()\n","\tloaded_model = model_from_json(loaded_model_json)\n","\t# load weights into new model\n","\tloaded_model.load_weights(\"model.h5\")\n","\tloaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\treturn loaded_model"],"metadata":{"id":"a5HyGZk6jDNz","executionInfo":{"status":"ok","timestamp":1707702487528,"user_tz":180,"elapsed":14,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Função que cria a estrutura com os parametros para treinar o modelo"],"metadata":{"id":"RFbUJ6UX_lE3"}},{"cell_type":"code","source":["def train(train_generator, val_generator):\n","\t#STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","\t#STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n","\n","\tprint('[LOG] Intialize Neural Network')\n","\n","\tmodel = Sequential()\n","\n","\tmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))\n","\tmodel.add(MaxPooling2D((2,2)))\n","\n","\tmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2)))\n","\n","\tmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n","\tmodel.add(MaxPooling2D((2,2)))\n","\n","\tmodel.add(Flatten())\n","\n","\tmodel.add(Dense(units=512, activation='relu'))\n","\tmodel.add(Dense(units=120, activation='relu'))\n","\tmodel.add(Dense(units=60, activation='relu'))\n","\tmodel.add(Dense(units=1, activation = 'sigmoid'))\n","\n","\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\tmodel.fit_generator(generator=train_generator,\n","\t                    steps_per_epoch=1,\n","\t                    validation_data=val_generator,\n","\t                    validation_steps=1,\n","\t                    epochs=25\n","\t)\n","\n","\tsave_model(model)\n","\treturn model"],"metadata":{"id":"tVfbXzTGjFpj","executionInfo":{"status":"ok","timestamp":1707702487824,"user_tz":180,"elapsed":309,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Função para dividir o video em frames e cada frame será analisado pelo modelo para validar se é ou não uma imagem fake (caso tenha 60% de frames não fake, então a função vai retorna que não é fake)"],"metadata":{"id":"PW3OhRnPADIY"}},{"cell_type":"code","source":["def process_video_frames(video_path):\n","    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    person_count = 0\n","\n","    for _ in tqdm(range(frame_count)):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","\n","        if len(faces) > 0:\n","            # Processar o frame como uma imagem para o modelo\n","            img = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n","            img = np.array(img) / 255.0\n","            img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n","\n","            # Usar o modelo para prever se é uma pessoa ou não\n","            prediction = loaded_model.predict(img)\n","            if prediction > 0.5:  # Se a previsão for maior que 0.5, consideramos como uma pessoa\n","                person_count += 1\n","\n","    cap.release()\n","\n","    if person_count / frame_count >= 0.6:\n","        return \"É uma pessoa.\"\n","    else:\n","        return \"Enviar o caso para a analise.\""],"metadata":{"id":"S9tG6ymJ0ZqM","executionInfo":{"status":"ok","timestamp":1707702487825,"user_tz":180,"elapsed":310,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Funções para identificar se tem alguma frame com a pessoa seria e depois sorrindo"],"metadata":{"id":"Zgc21LYsAkaw"}},{"cell_type":"code","source":["def detect_smile(frame):\n","    smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    smiles = smile_cascade.detectMultiScale(gray, scaleFactor=1.8, minNeighbors=20)\n","    return len(smiles) > 0\n","\n","def validate_smile_frames(video_path):\n","    smile_detected = False\n","    no_smile_detected = False\n","\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    for _ in tqdm(range(frame_count)):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        if detect_smile(frame):\n","            smile_detected = True\n","        else:\n","            no_smile_detected = True\n","\n","        if smile_detected and no_smile_detected:\n","            cap.release()\n","            return \"Cadastro aceito.\"\n","\n","    cap.release()\n","    return \"Enviado para análise.\""],"metadata":{"id":"h65ANCXT36ng","executionInfo":{"status":"ok","timestamp":1707701622761,"user_tz":180,"elapsed":348,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Treinado o modelo para verificar se é uma imagem fake ou não"],"metadata":{"id":"jV_xDEYQAznh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_ET99HKCYdO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707698884248,"user_tz":180,"elapsed":62111,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}},"outputId":"eaac030d-0ee4-4711-81e9-ca57313101e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 24 images belonging to 2 classes.\n","Found 11 images belonging to 2 classes.\n","[LOG] Intialize Neural Network\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-03cce2978406>:27: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(generator=train_generator,\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","1/1 [==============================] - 6s 6s/step - loss: 0.6935 - accuracy: 0.4583 - val_loss: 0.6888 - val_accuracy: 0.5455\n","Epoch 2/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.6895 - accuracy: 0.5417 - val_loss: 0.6858 - val_accuracy: 0.5455\n","Epoch 3/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.6863 - accuracy: 0.5417 - val_loss: 0.6826 - val_accuracy: 0.5455\n","Epoch 4/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.6843 - accuracy: 0.5417 - val_loss: 0.6806 - val_accuracy: 0.5455\n","Epoch 5/25\n","1/1 [==============================] - 3s 3s/step - loss: 0.6814 - accuracy: 0.5417 - val_loss: 0.6768 - val_accuracy: 0.5455\n","Epoch 6/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.6787 - accuracy: 0.5417 - val_loss: 0.6734 - val_accuracy: 0.5455\n","Epoch 7/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.6727 - accuracy: 0.5417 - val_loss: 0.6694 - val_accuracy: 0.5455\n","Epoch 8/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.6663 - accuracy: 0.5417 - val_loss: 0.6621 - val_accuracy: 0.5455\n","Epoch 9/25\n","1/1 [==============================] - 3s 3s/step - loss: 0.6575 - accuracy: 0.5417 - val_loss: 0.6489 - val_accuracy: 0.5455\n","Epoch 10/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.6455 - accuracy: 0.5417 - val_loss: 0.6338 - val_accuracy: 0.5455\n","Epoch 11/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.6301 - accuracy: 0.5417 - val_loss: 0.6251 - val_accuracy: 0.5455\n","Epoch 12/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.6099 - accuracy: 0.7500 - val_loss: 0.6076 - val_accuracy: 0.5455\n","Epoch 13/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.5928 - accuracy: 0.7083 - val_loss: 0.5751 - val_accuracy: 0.7273\n","Epoch 14/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.5678 - accuracy: 0.8333 - val_loss: 0.5748 - val_accuracy: 0.5455\n","Epoch 15/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.5396 - accuracy: 0.7500 - val_loss: 0.5044 - val_accuracy: 1.0000\n","Epoch 16/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.5244 - accuracy: 0.8333 - val_loss: 0.5099 - val_accuracy: 0.7273\n","Epoch 17/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.4936 - accuracy: 0.7917 - val_loss: 0.4796 - val_accuracy: 0.7273\n","Epoch 18/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.4646 - accuracy: 0.8333 - val_loss: 0.4206 - val_accuracy: 0.9091\n","Epoch 19/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.4497 - accuracy: 0.8333 - val_loss: 0.4478 - val_accuracy: 0.7273\n","Epoch 20/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.4123 - accuracy: 0.8750 - val_loss: 0.3857 - val_accuracy: 0.8182\n","Epoch 21/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.3862 - accuracy: 0.8333 - val_loss: 0.3329 - val_accuracy: 0.9091\n","Epoch 22/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.3310 - accuracy: 0.8750 - val_loss: 0.4428 - val_accuracy: 0.7273\n","Epoch 23/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.3760 - accuracy: 0.8333 - val_loss: 0.2969 - val_accuracy: 1.0000\n","Epoch 24/25\n","1/1 [==============================] - 1s 1s/step - loss: 0.3717 - accuracy: 0.7500 - val_loss: 0.3557 - val_accuracy: 0.7273\n","Epoch 25/25\n","1/1 [==============================] - 2s 2s/step - loss: 0.2888 - accuracy: 0.8750 - val_loss: 0.5158 - val_accuracy: 0.7273\n"]}],"source":["train_generator, val_generator = collect()\n","model = train(train_generator, val_generator)"]},{"cell_type":"markdown","metadata":{"id":"SXorQTryCYdM"},"source":["### 4.3 Métricas de desempenho do modelo (2 pontos)"]},{"cell_type":"markdown","source":["Métricas do modelo"],"metadata":{"id":"H4lW2PAZA9Tu"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"ObRmYDMXu5H3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707698962690,"user_tz":180,"elapsed":606,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}},"outputId":"904564c3-09e5-465d-bf2f-52d04a8678d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_9 (Conv2D)           (None, 22, 22, 32)        320       \n","                                                                 \n"," max_pooling2d_9 (MaxPoolin  (None, 11, 11, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 9, 9, 64)          18496     \n","                                                                 \n"," max_pooling2d_10 (MaxPooli  (None, 4, 4, 64)          0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 2, 2, 128)         73856     \n","                                                                 \n"," max_pooling2d_11 (MaxPooli  (None, 1, 1, 128)         0         \n"," ng2D)                                                           \n","                                                                 \n"," flatten_3 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 512)               66048     \n","                                                                 \n"," dense_13 (Dense)            (None, 120)               61560     \n","                                                                 \n"," dense_14 (Dense)            (None, 60)                7260      \n","                                                                 \n"," dense_15 (Dense)            (None, 1)                 61        \n","                                                                 \n","=================================================================\n","Total params: 227601 (889.07 KB)\n","Trainable params: 227601 (889.07 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"QMuUpiqTCYdQ"},"source":["## 5 Teste Fim-a-Fim\n","\n","Simule a operação fim-a-fim, com uma imagem de entrada forjada (foto de foto de um rosto) e outra com uma imagem de rosto, exibindo o resultado da classificação e a pontuação de cada classe."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"ZXuv686NCYdR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707701919871,"user_tz":180,"elapsed":203514,"user":{"displayName":"Marky Santana","userId":"10663892479234473558"}},"outputId":"faac61f4-19aa-4021-e603-16bbe23c265b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 144/144 [01:35<00:00,  1.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Rostos identificados no vídeo. Iniciando processamento...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/144 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 1/144 [00:00<01:51,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 2/144 [00:01<01:39,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 3/144 [00:02<01:34,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 4/144 [00:02<01:32,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 5/144 [00:03<01:31,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 6/144 [00:04<01:30,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 7/144 [00:04<01:30,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 8/144 [00:05<01:29,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▋         | 9/144 [00:06<01:33,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 10/144 [00:07<01:47,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 11/144 [00:08<01:57,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 12/144 [00:09<01:53,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 13/144 [00:09<01:45,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 14/144 [00:10<01:38,  1.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 15/144 [00:11<01:35,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 16/144 [00:11<01:32,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 17/144 [00:12<01:29,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 18/144 [00:13<01:27,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 19/144 [00:13<01:26,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 20/144 [00:14<01:24,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 21/144 [00:15<01:23,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 22/144 [00:15<01:23,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 23/144 [00:16<01:22,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 24/144 [00:17<01:22,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 25/144 [00:17<01:22,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 26/144 [00:18<01:20,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 27/144 [00:19<01:30,  1.30it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 28/144 [00:20<01:40,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 29/144 [00:21<01:44,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 30/144 [00:22<01:35,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 31/144 [00:22<01:28,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 32/144 [00:23<01:23,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 33/144 [00:24<01:20,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▎       | 34/144 [00:24<01:17,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 35/144 [00:25<01:16,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 36/144 [00:26<01:15,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 37/144 [00:26<01:13,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▋       | 38/144 [00:27<01:12,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 39/144 [00:28<01:12,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 40/144 [00:28<01:11,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 41/144 [00:29<01:10,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 42/144 [00:30<01:10,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 43/144 [00:31<01:09,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 44/144 [00:31<01:12,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 45/144 [00:33<01:24,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 46/144 [00:34<01:29,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 47/144 [00:34<01:24,  1.15it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 48/144 [00:35<01:18,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 49/144 [00:36<01:13,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 50/144 [00:36<01:10,  1.33it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 51/144 [00:37<01:08,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 52/144 [00:38<01:06,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 53/144 [00:38<01:04,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 54/144 [00:39<01:03,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 55/144 [00:40<01:02,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 56/144 [00:41<01:01,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 57/144 [00:41<01:00,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 58/144 [00:42<00:59,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 59/144 [00:43<00:58,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 60/144 [00:43<00:58,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 61/144 [00:44<01:00,  1.37it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 62/144 [00:45<01:09,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 63/144 [00:46<01:13,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 64/144 [00:47<01:09,  1.16it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 65/144 [00:48<01:04,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 66/144 [00:48<01:00,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 67/144 [00:49<00:57,  1.33it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 68/144 [00:50<00:55,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 69/144 [00:51<00:54,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 70/144 [00:51<00:53,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 71/144 [00:52<00:51,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 72/144 [00:53<00:50,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 73/144 [00:53<00:49,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 74/144 [00:54<00:49,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 75/144 [00:55<00:48,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 76/144 [00:55<00:47,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 77/144 [00:56<00:46,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 78/144 [00:57<00:48,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 79/144 [00:58<00:54,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 33ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 80/144 [00:59<00:58,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▋    | 81/144 [01:00<00:56,  1.12it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 82/144 [01:01<00:51,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 83/144 [01:01<00:48,  1.27it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 84/144 [01:02<00:45,  1.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 85/144 [01:03<00:43,  1.35it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 86/144 [01:03<00:42,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 87/144 [01:04<00:41,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 88/144 [01:05<00:40,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 89/144 [01:05<00:39,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 90/144 [01:06<00:38,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 91/144 [01:07<00:37,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 92/144 [01:08<00:36,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 93/144 [01:08<00:35,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 94/144 [01:09<00:34,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 95/144 [01:10<00:35,  1.37it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 96/144 [01:11<00:40,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 97/144 [01:12<00:43,  1.09it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 98/144 [01:13<00:40,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 99/144 [01:13<00:36,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 100/144 [01:14<00:34,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 101/144 [01:15<00:32,  1.33it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 102/144 [01:15<00:30,  1.37it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 103/144 [01:16<00:29,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 104/144 [01:17<00:28,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 23ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 105/144 [01:18<00:27,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▎  | 106/144 [01:18<00:26,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 107/144 [01:19<00:25,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 25ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 108/144 [01:20<00:24,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 109/144 [01:20<00:23,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▋  | 110/144 [01:21<00:23,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 27ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 111/144 [01:22<00:22,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 112/144 [01:22<00:22,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 30ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 113/144 [01:23<00:25,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 114/144 [01:25<00:27,  1.11it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 115/144 [01:25<00:25,  1.13it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 116/144 [01:26<00:22,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████▏ | 117/144 [01:27<00:20,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 118/144 [01:27<00:19,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 119/144 [01:28<00:18,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 120/144 [01:29<00:16,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 121/144 [01:29<00:16,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 122/144 [01:30<00:15,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 123/144 [01:31<00:14,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 124/144 [01:31<00:13,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 125/144 [01:32<00:13,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 126/144 [01:33<00:12,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 127/144 [01:33<00:11,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 128/144 [01:34<00:10,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 129/144 [01:35<00:10,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 130/144 [01:36<00:10,  1.32it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 131/144 [01:37<00:11,  1.17it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 132/144 [01:38<00:10,  1.10it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 133/144 [01:39<00:09,  1.19it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 134/144 [01:39<00:07,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 135/144 [01:40<00:06,  1.31it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 136/144 [01:41<00:05,  1.35it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 137/144 [01:41<00:05,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 138/144 [01:42<00:04,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 139/144 [01:43<00:03,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 140/144 [01:43<00:02,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 141/144 [01:44<00:02,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▊| 142/144 [01:45<00:01,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 143/144 [01:45<00:00,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 144/144 [01:46<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["É uma pessoa.\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/144 [00:00<01:38,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["Cadastro aceito.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["if __name__ == '__main__':\n","    video_path = \"/content/computer_vision/entrada/20240211_211634.mp4\"\n","    if detect_faces_in_video(video_path):\n","        print(\"Rostos identificados no vídeo. Iniciando processamento...\")\n","        loaded_model = load_model()\n","        result = process_video_frames(video_path)\n","        print(result)\n","        if result == \"É uma pessoa.\":\n","            validation_result = validate_smile_frames(video_path)\n","            print(validation_result)\n","    else:\n","        print(\"Rostos não identificados no vídeo.\")"]},{"cell_type":"markdown","metadata":{"id":"jtBe5cIACYdT"},"source":[">Com a implementação da solução na forma de uma aplicação do [Streamlit](https://www.streamlit.io/) (veja a pata streamlit-app e use o template) vale 1 ponto adicional."]},{"cell_type":"markdown","metadata":{"id":"IlRMfIXeCYdU"},"source":["**Pergunta**: Se utilizou o Streamlit, compartilhe a URL do aplicativo publicado:"]},{"cell_type":"markdown","metadata":{"id":"VHf06ughCYdU"},"source":["**Resposta**:"]},{"cell_type":"markdown","metadata":{"id":"mHvjsUKxCYdV"},"source":["## 6 Conclusões (2,5 pontos)\n","\n","**Pergunta**: Dado todo o estudo e pesquisa, quais foram as conclusões sobre a solução, o que funcionou, o que não funcionou e quais os detalhes que observariam numa nova versão e melhorias do processo?"]},{"cell_type":"markdown","metadata":{"id":"e12yTB8yCYdV"},"source":["**Resposta**:"]},{"cell_type":"markdown","source":["É possível concluir que tanto a prova de vida, quanto a detecção rostos ou parte do rosto em uma imagem ou video, é possível utilizando alguns recursos atraves de bibliteca como CV2, Keras e modelos como haarcascade, implementando em soluções reais, para solucionar risco previnindo possiveis fraudes.\n","\n","O que funcionou: Tivemos sucesso no treinamento do modelo para identificar o rosto real de um rosto fake e a validação dos modelos de rosto e sorriso.\n","\n","O que não funcionou: Apresentar em tempo real as sequencias de imagens do video, com a aplicação da identificação das área dos rostos e sorrisos, apresentado para o cliente a execução do processo de seu video.\n","\n","Melhorias:\n","- Otimizar o código para rodar em tempo real.\n","- Adicionar mais validações como os olhos piscando."],"metadata":{"id":"YFYG7Z3ZBaLH"}},{"cell_type":"code","source":[],"metadata":{"id":"AedaVU1oDSFy"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"733a071da2455ea0e8bdf5409a7097e630ac701195faf55c6e985d77ee3ec176"}},"colab":{"provenance":[{"file_id":"https://github.com/michelpf/fiap-ml-visao-computacional-detector-liveness/blob/master/notebook/deteccao-liveness-notebook.ipynb","timestamp":1707694346441}]}},"nbformat":4,"nbformat_minor":0}